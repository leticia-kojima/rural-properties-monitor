# Projeto Hackathon para Monitoramento de Propriedades Rurais

## Sum√°rio

- [Vis√£o Geral](#vis√£o-geral)
- [Componentes](#componentes)
- [Fluxo Geral de Dados](#fluxo-geral-de-dados)
- [Infraestrutura como C√≥digo (IaC)](#infraestrutura-como-c√≥digo-iac)
  - [Como iniciar todos os servi√ßos](#como-iniciar-todos-os-servi√ßos)
  - [Como iniciar apenas servi√ßos espec√≠ficos](#como-iniciar-apenas-servi√ßos-espec√≠ficos)
  - [Como parar e remover os containers](#como-parar-e-remover-os-containers)
- [Kubernetes & Minikube](#kubernetes--minikube)
- [Autores](#autores)

## Vis√£o Geral

O sistema √© composto por uma arquitetura baseada em microsservi√ßos, orientada a eventos e preparada para ingest√£o e an√°lise de dados de sensores em propriedades rurais. O diagrama abaixo representa os principais componentes e seus fluxos de comunica√ß√£o.

A proposta √© permitir que dados coletados em campo (sensores) sejam ingeridos, armazenados, processados e posteriormente consumidos por produtores rurais atrav√©s de uma API centralizada.

![Diagrama da Arquitetura](architecture-diagram.drawio.png)

## Componentes

### üë§ Rural Producer

Representa o usu√°rio final (produtor rural), que consome os dados e insights por meio da **Analytics API**.

---

### üî∑ Analytics API

Servi√ßo respons√°vel por consolidar e disponibilizar dados anal√≠ticos ao usu√°rio final.

Fun√ß√µes principais:

* Receber requisi√ß√µes HTTP do produtor rural
* Consultar dados em batch em outros servi√ßos
* Utilizar o **Redis** como cache para melhorar performance
* Orquestrar chamadas para:

  * **Properties API** (dados cadastrais)
  * **Ingress API** (dados de sensores)

---

### üü• Redis

Utilizado como camada de cache para a **Analytics API**, reduzindo lat√™ncia e evitando consultas repetidas aos servi√ßos dependentes.

---

### üî∑ Properties API

Respons√°vel pelo gerenciamento de dados relacionados √†s propriedades rurais.

Fun√ß√µes principais:

* Cadastro e consulta de propriedades
* Persist√™ncia dos dados no **MongoDB**

---

### üü™ MongoDB

Banco de dados NoSQL utilizado para armazenar os dados estruturais e cadastrais das propriedades.

---

### üî∑ Ingress API

Servi√ßo respons√°vel pela ingest√£o e processamento dos dados vindos dos sensores.

Fun√ß√µes principais:

* Consumir eventos provenientes do **Kafka**
* Processar dados de telemetria
* Persistir s√©ries temporais no **InfluxDB**
* Disponibilizar dados para consumo da **Analytics API**

---

### üü¶ InfluxDB

Banco de dados de s√©ries temporais utilizado para armazenar os dados dos sensores processados pela **Ingress API**.

Fun√ß√µes principais:

* Armazenamento otimizado para dados de s√©ries temporais
* Consultas eficientes baseadas em tempo
* Reten√ß√£o autom√°tica de dados
* Interface web para visualiza√ß√£o e consulta (http://localhost:8086)

Dados armazenados:
* Umidade do solo
* Temperatura
* Precipita√ß√£o
* Timestamp dos sensores

---

### üüß Kafka

Plataforma de mensageria utilizada como broker de eventos entre os sensores e a **Ingress API**.

Benef√≠cios:

* Comunica√ß√£o ass√≠ncrona
* Maior resili√™ncia
* Escalabilidade no processamento de eventos

---

### üìü Sensors

Representam dispositivos de campo respons√°veis pela coleta de dados (ex: temperatura, umaidade, localiza√ß√£o, etc.).

Esses dados s√£o enviados para o Kafka, simulando um cen√°rio real de IoT.

---

### üõ°Ô∏è Keycloak

Respons√°vel pela autentica√ß√£o e autoriza√ß√£o dos usu√°rios e servi√ßos.

Fun√ß√µes principais:

* Gerenciamento de identidade (IAM)
* Emiss√£o e valida√ß√£o de tokens (OAuth2 / OpenID Connect)
* Integra√ß√£o com banco PostgreSQL

---

### üêò PostgreSQL

Banco de dados utilizado pelo **Keycloak** para persist√™ncia de usu√°rios, credenciais e configura√ß√µes de seguran√ßa.

---

## Fluxo Geral de Dados

1. Sensores enviam dados ‚Üí **Kafka**
2. **Ingress API** consome os eventos e armazena no **InfluxDB**
3. **Properties API** gerencia dados cadastrais no **MongoDB**
4. **Analytics API** consulta os dois servi√ßos em batch
5. Resultados s√£o cacheados no **Redis**
6. O produtor rural consome os dados via requisi√ß√µes HTTP

## Infraestrutura como C√≥digo (IaC)

O projeto utiliza Docker Compose para orquestrar todos os servi√ßos. O arquivo principal [`docker-compose.yml`](docker-compose.yml) est√° na raiz do projeto e inclui os arquivos de defini√ß√£o de cada servi√ßo localizados na pasta [`iac`](iac/):

- [`iac/analytics-docker-compose.yml`](iac/analytics-docker-compose.yml)
- [`iac/ingress-docker-compose.yml`](iac/ingress-docker-compose.yml)
- [`iac/keycloak-docker-compose.yml`](iac/keycloak-docker-compose.yml)
- [`iac/properties-docker-compose.yml`](iac/properties-docker-compose.yml)
- [`iac/sensors-docker-compose.yml`](iac/sensors-docker-compose.yml)

### Como iniciar todos os servi√ßos

No terminal, acesse a raiz do projeto (onde est√° o arquivo `docker-compose.yml`) e execute:

```sh
docker compose up -d
```

Isso ir√° iniciar todos os servi√ßos definidos nos arquivos de compose inclu√≠dos.

### Como iniciar apenas servi√ßos espec√≠ficos

Voc√™ pode subir apenas um servi√ßo (e suas depend√™ncias) usando:

```sh
docker compose up -d <nome-do-servi√ßo>
```

Por exemplo, para subir apenas o servi√ßo de sensores:

```sh
docker compose up -d sensors
```

> Certifique-se de que os arquivos de compose individuais estejam devidamente configurados com os servi√ßos necess√°rios.

### Como parar e remover os containers

Para parar todos os containers:

```sh
docker compose stop
```

Para parar e remover todos os containers, redes e volumes criados:

```sh
docker compose down
```

Voc√™ tamb√©m pode usar essas op√ß√µes com arquivos de compose personalizados usando a op√ß√£o `-f`.

## Kubernetes & Minikube

Esta se√ß√£o orienta como executar e orquestrar todos os microsservi√ßos do projeto em um cluster Kubernetes local utilizando o Minikube. O uso do Kubernetes permite simular um ambiente de produ√ß√£o real, facilitando testes de escalabilidade, resili√™ncia, deploy cont√≠nuo e integra√ß√£o entre os servi√ßos. Com Minikube, voc√™ pode experimentar pr√°ticas modernas de DevOps, validar a infraestrutura como c√≥digo e garantir que sua aplica√ß√£o est√° pronta para ambientes cloud-native.

### O que √© Minikube?
Minikube √© uma ferramenta que executa clusters Kubernetes localmente, ideal para desenvolvimento e testes.

### Por que usar Kubernetes neste projeto?
- Orquestra√ß√£o e automa√ß√£o de deploys, escalonamento e gerenciamento dos servi√ßos.
- Simula√ß√£o de ambiente produtivo, com pods, servi√ßos, volumes persistentes e vari√°veis de ambiente.
- Facilidade para testar cen√°rios de falha, escalabilidade e atualiza√ß√£o cont√≠nua.
- Separa√ß√£o clara dos recursos de infraestrutura (Kafka, InfluxDB, Zookeeper, etc) e dos microsservi√ßos da aplica√ß√£o.

### Organiza√ß√£o dos Manifests

Os manifests do Kubernetes est√£o organizados em subpastas dentro de `k8s/`:

- `k8s/influxdb/` - Deployment, Service, PVCs do InfluxDB
- `k8s/kafka/` - Deployment & Service do Kafka
- `k8s/zookeeper/` - Deployment & Service do Zookeeper
- `k8s/ingress/` - Deployment & Service da API Ingress

Cada subpasta cont√©m arquivos YAML separados para Deployment, Service e, quando necess√°rio, PersistentVolumeClaim.

### Como rodar no Minikube

1. **Inicie o Minikube:**
   ```sh
   minikube start
   ```
2. **Construa as imagens Docker dentro do Minikube:**
   - **Op√ß√£o 1: Build de todas as imagens com Docker Compose:**
     ```sh
     eval $(minikube docker-env)
     docker compose build
     ```
   - **Op√ß√£o 2: Build manual de cada imagem:**
     ```sh
     eval $(minikube docker-env)
     docker build -t ingress:latest ./src/Ingress
     # Construa outras imagens conforme necess√°rio
     ```
3. **Aplique os manifests do Kubernetes:**
   - **Op√ß√£o 1: Aplicar todos os manifests de uma vez:**
     ```sh
     kubectl apply -f k8s/
     ```
   - **Op√ß√£o 2: Aplicar manualmente cada manifest:**
     ```sh
     kubectl apply -f k8s/zookeeper/zookeeper-deployment.yaml
     kubectl apply -f k8s/zookeeper/zookeeper-service.yaml
     kubectl apply -f k8s/kafka/kafka-deployment.yaml
     kubectl apply -f k8s/kafka/kafka-service.yaml
     kubectl apply -f k8s/influxdb/influxdb-pvc.yaml
     kubectl apply -f k8s/influxdb/influxdb-deployment.yaml
     kubectl apply -f k8s/influxdb/influxdb-service.yaml
     kubectl apply -f k8s/ingress/ingress-api-deployment.yaml
     kubectl apply -f k8s/ingress/ingress-api-service.yaml
     ```
4. **Verifique os pods e servi√ßos:**
   ```sh
   kubectl get pods
   kubectl get svc
   ```
5. **Acesse a API ingress:**
   ```sh
   minikube service ingress-api
   ```

### Dicas e Boas Pr√°ticas

- Use `kubectl delete -f <arquivo.yaml>` para remover recursos.
- Use `kubectl logs <nome-do-pod>` para debugar problemas em pods.
- Para acessar o InfluxDB, crie um port-forward:
  ```sh
  kubectl port-forward svc/influxdb 8086:8086
  ```
- Para testar escalabilidade, altere o campo `replicas` nos arquivos de Deployment.
- As vari√°veis de ambiente definidas nos Deployments sobrescrevem as configura√ß√µes do `appsettings.json`.
- Certifique-se de que o valor de `InfluxDbConfig__Url` seja `http://influxdb:8086` no ambiente Kubernetes.

## Autores

- [Paulo](https://github.com/paulobusch)
- [Geovanne](https://github.com/gehcosta)
- [Let√≠cia](https://github.com/leticia-kojima)
- [Matheus](https://github.com/M4theusVieir4)
- [Marcelo](https://github.com/marceloalvees)
